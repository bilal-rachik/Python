{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ntroduction, Code Formatting, and Tools.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtswKhBp3o9_"
      },
      "source": [
        "# ntroduction, Code Formatting, and Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gws68Pof3twB"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Nous commencerons d'abord par comprendre ce qu'est un code propre et pourquoi c'est important pour qu'un projet de génie logiciel réussisse. Dans les deux premières sections, nous apprendrons à quel point il est important de maintenir une bonne qualité de code afin de travailler efcacement. efficace de ne pas refactoriser notre code pour rembourser toute sa dette technique. Après tout, nous ne pouvons pas simplement nous attendre à ce que des règles générales s'appliquent partout, car nous savons qu'il existe des exceptions. L'important ici est de bien comprendre pourquoi nous serions prêts à faire une exception et d'identifier correctement ce genre de situations. Nous ne voudrions pas nous tromper en pensant que quelque chose ne devrait pas être amélioré alors qu'en fait cela devrait.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxId3ocy5r2a"
      },
      "source": [
        "## La signification du code propre.\n",
        "\n",
        "Il n'y a pas de dénition unique ou stricte de code propre. De plus, il n'y a probablement aucun moyen de mesurer formellement un code propre, vous ne pouvez donc pas exécuter un outil sur un référentiel qui vous dira à quel point ce code est bon, mauvais ou maintenable. Bien sûr, vous pouvez exécuter des outils tels que des **checkers**, des linters, des analyseurs statiques, etc., et ces outils sont d'une grande aide. Ils sont nécessaires, mais pas suffisants. Un code propre n'est pas quelque chose qu'une machine ou un script peut reconnaître (jusqu'à présent) mais plutôt quelque chose que nous, en tant que professionnels, pouvons décider. Pendant des décennies d'utilisation du terme langages de programmation, nous avons pensé qu'ils étaient destinés à communiquer nos idées aux machines afin qu'elles peut exécuter nos programmes. Nous avions tort. Ce n'est pas la vérité, mais une partie de la vérité. Le vrai sens de la partie \"langage\" des \"langages de programmation\" est de communiquer nos idées à d'autres développeurs.\n",
        "\n",
        "C'est là que réside la vraie nature du code propre. Cela dépend des autres ingénieurs pour pouvoir lire et maintenir le code. Par conséquent, nous, en tant que professionnels, sommes les seuls à pouvoir en juger. Pensez-y; en tant que développeurs, nous passons beaucoup plus de temps à lire du code qu'à l'écrire réellement. Chaque fois que nous voulons apporter une modification ou ajouter une nouvelle fonctionnalité, nous devons d'abord lire tout l'environnement du code que nous devons modifier ou étendre. Le langage (Python) est ce que nous utilisons pour communiquer entre nous. Alors, au lieu de vous donner une dénition (ou ma définition) du code propre, je vous invite à parcourir ce repo, lire tout sur Python idiomatique, voyez la différence entre un bon et un mauvais code, identifiez les caractéristiques d'un bon code et d'une bonne architecture, puis proposez votre propre dénition. Après avoir lu ce repo, vous serez en mesure de juger et d'analyser le code par vous-même, et vous aurez une meilleure compréhension du code propre. Vous saurez ce que c'est et ce que cela signifie, quelle que soit la définition qui vous est donnée.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1b3QTm27Gko"
      },
      "source": [
        "## L'importance d'avoir un code propre\n",
        "\n",
        "Il existe un grand nombre de raisons pour lesquelles un code propre est important. La plupart d'entre eux tournent autour des idées de maintenabilité, de réduction de la dette technique, de travail efficace avec le développement agile et de gestion d'un projet réussi. La première idée que j'aimerais explorer concerne le développement agile et la livraison continue. Si nous voulons que notre projet fournisse avec succès des fonctionnalités à un rythme constant et prévisible, il est alors indispensable de disposer d'une bonne base de code et maintenable.\n",
        "\n",
        "Imaginez que vous conduisez une voiture sur une route vers une destination que vous souhaitez atteindre à un certain moment. Vous devez estimer votre heure d'arrivée afin de pouvoir prévenir la personne qui vous attend. Si la voiture fonctionne correctement et que la route est plate et parfaite, alors je ne vois pas pourquoi vous manqueriez beaucoup votre estimation. Cependant, si la route est en mauvais état et que vous devez sortir pour écarter les rochers ou éviter les fissures, arrêtez-vous pour vérifier le moteur tous les quelques kilomètres, il est très peu probable que vous sachiez avec certitude quand vous êtes arriver (ou si vous arriverez). Je pense que l'analogie est claire; la route est le code. Si vous souhaitez évoluer à un rythme régulier, constant et prévisible, le code doit être maintenable et lisible. Si ce n'est pas le cas, chaque fois que la gestion des produits demande une nouvelle fonctionnalité, vous devrez arrêter de refactoriser et de corriger la dette technique. La dette technique fait référence à la notion de problèmes dans le logiciel à la suite d'un compromis ou d'une mauvaise décision. etre fait. Il est possible de penser à la dette technique de deux manières. Du présent au passé : et si les problèmes auxquels nous sommes actuellement confrontés étaient le résultat d'un mauvais code précédemment écrit ? Et, du présent au futur : si nous décidons de prendre un raccourci maintenant, au lieu d'investir du temps dans une solution appropriée, quels problèmes nous créons-nous plus tard ?\n",
        "\n",
        "Le mot dette est un bon choix. C'est une dette parce que le code sera plus difficile à changer à l'avenir qu'il ne le serait de le changer maintenant. Ce coût encouru est l'intérêt de la dette. Encourir une dette technique signifie que demain, le code sera plus difficile et plus cher à changer qu'aujourd'hui, et encore plus cher lendemain, et ainsi de suite. A chaque fois l'équipe ne peut pas livrer quelque chose à temps et doit s'arrêter pour corriger et refactoriser le code, cela paie le prix de la dette technique. On pourrait même affirmer qu'une équipe qui possède une base de code avec une dette technique ne fait pas de développement logiciel agile. Car, quel est le contraire d'agile ? Rigide. Si le code est truffé d'odeurs de code, il ne peut pas être facilement modifié, il n'y a donc aucun moyen pour l'équipe de réagir rapidement aux changements d'exigences et de livrer en continu. Le pire avec la dette technique est qu'elle représente un long -terme et problème sous-jacent. Ce n'est pas quelque chose qui sonne l'alarme. Au lieu de cela, c'est un problème silencieux, dispersé dans toutes les parties du projet, qui un jour, à un moment particulier, se réveillera et deviendra un show-stopper.\n",
        "\n",
        "Dans certains cas plus alarmants, la « dette technique » est même un euphémisme, car le problème est bien pire. Dans les paragraphes précédents, j'ai évoqué des scénarios dans lesquels la dette technique rend les choses plus difficiles pour l'équipe à l'avenir, mais que se passe-t-il si la réalité est beaucoup plus dangereuse ? Imaginez que vous preniez un raccourci qui laisse le code dans une position fragile. Vous pouvez déployer votre code et il fonctionnera correctement pendant un certain temps (tant que ce défaut ne se manifeste pas). Mais c'est en fait un crash qui attend : un jour, quand on s'y attend le moins, une certaine condition dans le code sera remplie, ce qui causera un problème d'exécution avec l'application, comme une bombe à retardement à l'intérieur du code qui se déclenche à un moment aléatoire .Nous voudrions clairement éviter des scénarios comme celui-ci. Tout ne peut pas être attrapé par des outils automatisés, mais chaque fois que c'est possible, c'est un bon investissement. Le reste repose sur de bonnes revues de code approfondies et de bons tests automatisés.\n",
        "\n",
        "Le logiciel n'est utile que dans la mesure où il peut être facilement modifié. Pensez-y. Nous créons des logiciels pour répondre à certains besoins (qu'il s'agisse d'acheter un billet d'avion, de faire des achats en ligne, ou d'écouter de la musique, pour ne citer que quelques exemples). Ces exigences sont rarement figées, ce qui signifie que le logiciel devra être mis à jour dès que quelque chose dans le contexte qui a conduit à l'écriture de ce logiciel change en premier lieu. Si le code ne peut pas être modifié (et nous savons que la réalité change), alors c'est inutile. Avoir une base de code propre est une exigence absolue pour qu'elle soit modiée, d'où l'importance d'un code propre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjuCA55y-rKc"
      },
      "source": [
        "## Quelques exception\n",
        "\n",
        "Dans la section précédente, nous avons exploré le rôle essentiel d'une base de code propre dans la réussite d'un projet logiciel. Cela dit, rappelez-vous qu'il s'agit d'un article pour les praticiens, donc un lecteur pragmatique pourrait à juste titre souligner que cela soulève la question : « Y a-t-il des exceptions légitimes à cela ? » Et bien sûr, ce ne serait pas un article vraiment pragmatique s'il n'a pas permis au lecteur de remettre en cause certaines de ses hypothèses. En effet, il y a des cas dans lesquels vous voudrez peut-être penser à assouplir certaines des contraintes d'avoir une base de code vierge. Ce qui suit est une liste (en aucun cas exhaustive) de situations qui pourraient justifier l'omission de certains contrôles de qualité.\n",
        "\n",
        "* Hackathons\n",
        "* Si vous écrivez un script simple pour une tâche ponctuelle\n",
        "* Concours de code\n",
        "* Lors du développement d'une preuve de concept\n",
        "*  Lors du développement d'un prototype (tant que vous vous assurez qu'il s'agit bien d'un prototype qui sera jeté)\n",
        "*  Quand vous travaillez avec un ancien projet qui sera obsolète, et il n'est en mode maintenance que pour une période de temps xe et de courte durée (et encore une fois, à condition que cela soit assuré)\n",
        "\n",
        "Dans ces cas, le bon sens s'applique. Par exemple, si vous venez d'arriver à un projet qui ne sera opérationnel que pour les prochains mois jusqu'à ce qu'il soit mis hors service, alors cela ne vaut probablement pas la peine de vous donner la peine de régler toutes ses dettes techniques héritées et d'attendre qu'il être archivé pourrait être une meilleure option. Remarquez comment ces exemples ont tous en commun qu'ils supposent que le code peut se permettre de ne pas être écrit selon de bonnes normes de qualité est également un code que nous n'aurons jamais à revoir. \n",
        "\n",
        "Ceci est cohérent avec ce qui a été exposé précédemment et peut être considéré comme la contre-proposition de notre prémisse d'origine : que nous écrivons du code propre parce que nous voulons atteindre une maintenabilité élevée. S'il n'est pas nécessaire de maintenir ce code, nous pouvons ignorer l'effort de maintenir des normes de haute qualité dessus. \n",
        "\n",
        "N'oubliez pas que nous écrivons un code propre afin de pouvoir maintenir un projet. Cela signifie pouvoir modifier ce code nous-mêmes à l'avenir ou, si nous transférons la propriété de ce code à une autre équipe de l'entreprise, faciliter cette transition (et la vie des futurs mainteneurs). Cela signifie que si un projet est en mode maintenance uniquement, mais qu'il ne sera pas obsolète, cela peut toujours être un bon investissement pour rembourser sa dette technique. C'est parce qu'à un moment donné (et généralement quand on s'y attend le moins), il y aura un bogue qui devra être corrigé, et il serait bénéfique que le code soit aussi lisible que possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRwfFIslAZiy"
      },
      "source": [
        "## Formatage du code\n",
        "\n",
        "Le code propre ne concerne-t-il que le formatage et la structuration du code ? La réponse courte est non. Il existe des normes de codage comme PEP-8 (https://www.python.org/dev/peps/pep-0008/) qui indiquent comment le code doit être écrit et formaté. En Python, PEP-8 est la norme la plus connue, et ce document fournit des directives sur la façon dont nous devons écrire nos programmes, en termes d'espacement, de convention de nommage, de longueur de ligne, etc. bien au-delà des normes de codage, du formatage, des outils de linting et d'autres contrôles concernant la mise en page du code. Un code propre consiste à obtenir un logiciel de qualité et à créer un système robuste et maintenable. Un morceau de code ou un composant logiciel entier peut être 100% conforme à PEP-8 (ou à toute autre directive) et ne pas satisfaire à ces exigences. Même si le formatage n'est pas notre objectif principal, ne pas prêter attention à la structure du code présente certains dangers . Pour cette raison, nous allons d'abord analyser les problèmes avec une mauvaise structure de code et comment les résoudre. Après cela, nous verrons comment configurer et utiliser des outils pour les projets Python pour vérifier automatiquement les problèmes les plus courants.\n",
        "\n",
        "Pour résumer, nous pouvons dire que le code propre n'a rien à voir avec des choses comme PEP-8 ou les styles de codage. Cela va bien au-delà de cela, et c'est quelque chose de plus significatif pour la maintenabilité du code et la qualité du logiciel. Cependant, comme nous le verrons, formater correctement le code est important pour travailler efficacement.\n",
        "\n",
        "# Adhérer à un guide de style de codage sur votre projet\n",
        "\n",
        "Une directive de codage est un strict minimum qu'un projet devrait être considéré comme étant développé selon des normes de qualité. Dans cette section, nous allons explorer les raisons de cela. Dans les sections suivantes, nous pouvons commencer à chercher des moyens d'appliquer cela automatiquement à l'aide d'outils. La première chose qui me vient à l'esprit lorsque j'essaie de trouver de bons traits dans une disposition de code est la cohérence. Je m'attendrais à ce que le code soit structuré de manière cohérente afin qu'il soit facile à lire et à suivre. Si le code n'est pas correct ou structuré de manière cohérente, et que chaque membre de l'équipe fait les choses à sa manière, nous nous retrouverons avec un code qui nécessitera un effort et une concentration supplémentaires pour être compris. Ce sera source d'erreurs, trompeur, et des bugs ou des subtilités pourraient se glisser facilement.\n",
        "\n",
        "Nous voulons éviter cela. Ce que nous voulons, c'est exactement le contraire de cela : du code que nous pouvons lire et comprendre le plus rapidement possible d'un seul coup d'œil. familier. En conséquence, vous identifierez rapidement les modèles (plus d'informations à ce sujet dans une seconde), et avec ces modèles à l'esprit, il sera beaucoup plus facile de comprendre les choses et de détecter les erreurs. Par exemple, lorsque quelque chose ne va pas, vous remarquerez que, d'une manière ou d'une autre, il y a quelque chose d'étrange dans les schémas que vous avez l'habitude de voir, qui attirera votre attention. Vous regarderez de plus près et vous repérerez plus que probablement l'erreur ! identifier comment différentes personnes peuvent comprendre ou mémoriser différentes positions aux échecs. L'expérience a été menée sur des joueurs de tous niveaux (novices, intermédiaires et maîtres d'échecs), et avec différentes positions d'échecs sur l'échiquier. Ils ont découvert que lorsque la position était aléatoire, les novices faisaient aussi bien que les maîtres d'échecs ; c'était juste un exercice de mémorisation que n'importe qui pouvait faire raisonnablement au même niveau. Lorsque les positions suivaient une séquence logique qui pouvait se produire dans un jeu réel (encore une fois, cohérence, adhésion à un modèle), alors les maîtres d'échecs se sont comportés extrêmement mieux que les autres.\n",
        "\n",
        "Imaginez maintenant cette même situation appliquée au logiciel. Nous, en tant qu'ingénieurs logiciels experts en Python, sommes comme les maîtres d'échecs de l'exemple précédent. Lorsque le code est structuré de manière aléatoire, sans suivre aucune logique, ou adhérer à aucune norme, il serait alors aussi difficile pour nous de repérer les erreurs en tant que développeur novice. D'un autre côté, si nous sommes habitués à lire du code de manière structurée et que nous avons appris à tirer rapidement des idées du code en suivant des modèles, alors nous avons un avantage considérable. En particulier, pour Python, le type de codage le style que vous devez suivre est PEP-8. Vous pouvez l'étendre ou adapter certaines de ses parties aux particularités du projet sur lequel vous travaillez (par exemple, la longueur de la ligne, les notes sur les cordes, etc.). Si vous réalisez le projet sur lequel vous travaillez n'adhère à aucune norme de codage, poussez pour l'adoption de PEP-8 dans cette base de code. Idéalement, il devrait y avoir un document écrit pour l'entreprise ou l'équipe dans laquelle vous travaillez qui explique la norme de codage qui doit être suivie. Ces directives de codage peuvent être une adaptation de PEP-8.\n",
        "\n",
        "en particulier, PEP-8 aborde certains points importants pour les traits de qualité que vous ne voulez pas manquer dans votre projet ; certains d'entre eux sont : \n",
        "* La capacité de recherche : cela fait référence à la capacité d'identifier les jetons dans le code en un coup d'œil ; c'est-à-dire de rechercher dans certains fichiers (et dans quelle partie de ces fichiers) la chaîne particulière que nous recherchons. Un point clé de PEP-8 est qu'il différencie la manière d'écrire l'affectation des valeurs aux variables, des arguments mot-clés passés aux fonctions. Pour mieux voir cela, utilisons un exemple. Disons que nous déboguons et que nous devons trouver où la valeur d'un paramètre nommé location est transmise. Nous pouvons exécuter la commande grep suivante, et le résultat nous indiquera le fichier et la ligne que nous recherchons\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBLJEMqaD5Q_"
      },
      "source": [
        "! grep -nr \"location=\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73jCrv4vD9zC"
      },
      "source": [
        "Maintenant, nous voulons savoir où cette variable est affectée à cette valeur, et la commande suivante nous donnera également les informations que nous recherchons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFX_vLtHEBx8"
      },
      "source": [
        "!grep -nr \"location =\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lINtMTfZEL2P"
      },
      "source": [
        "PEP-8 établit la convention selon laquelle, lors du passage d'arguments par mot-clé à une fonction, nous n'utilisons pas d'espaces, mais nous le faisons lorsque nous affectons des valeurs à des variables. Pour cette raison, nous pouvons adapter nos critères de recherche (pas d'espace autour du = dans le premier exemple, et un espace dans le second) et être plus efcace dans notre recherche. C'est un des avantages de suivre une convention\n",
        "\n",
        "* **Cohérence** : Si le code a un format uniforme, la lecture de celui-ci sera beaucoup plus facile. Ceci est particulièrement important pour l'intégration, si vous souhaitez accueillir de nouveaux développeurs dans votre projet, ou même embaucher de nouveaux programmeurs (et probablement moins expérimentés) dans votre équipe, et ils doivent se familiariser avec le code (qui peut même consister en plusieurs référentiels ). Cela leur facilitera grandement la vie si la disposition du code, la documentation, la convention de nommage, etc. sont identiques dans tous les fichiers qu'ils ouvrent, dans tous les référentiels.\n",
        "\n",
        "* **Meilleure gestion des erreurs** : L'une des suggestions faites dans PEP-8 est de limiter la quantité de code à l'intérieur d'un bloc try/except au minimum possible. Cela réduit la surface d'erreur, dans le sens où cela réduit la probabilité d'avaler accidentellement une exception et de masquer un bogue. C'est, sans doute, peut-être difficile à appliquer par des vérifications automatiques, mais néanmoins quelque chose qui mérite d'être surveillé lors de la révision du code.\n",
        "\n",
        "* **Qualité du code** : En regardant le code de manière structurée, vous deviendrez plus compétent pour le comprendre en un coup d'œil (encore une fois, comme dans Perception in Chess), et vous repérerez plus facilement les bogues et les erreurs. En plus de cela, les outils qui vérifient la qualité du code indiqueront également des bogues potentiels. L'analyse statique du code peut aider à réduire le ratio de bogues par ligne de code.\n",
        "\n",
        "Comme je l'ai mentionné dans l'introduction, le formatage est une partie nécessaire du code propre, mais cela ne s'arrête pas là. Il y a plus de considérations à prendre en compte, telles que la documentation des décisions de conception dans le code et l'utilisation d'outils pour tirer le meilleur parti des contrôles de qualité automatiques. Dans la section suivante, nous commençons par le premier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50FNMfz7GG_a"
      },
      "source": [
        "## Documentation\n",
        "\n",
        "Cette section concerne la documentation du code en Python, à partir du code. Un bon code est explicite mais est également bien documenté. C'est une bonne idée d'expliquer ce qu'il est censé faire (pas comment). Une distinction importante : documenter le code n'est pas la même chose que d'y ajouter des commentaires. Cette section a l'intention d'explorer les docstrings et les annotations car ce sont les outils Python utilisés pour documenter le code. Cela dit, entre parenthèses, j'aborderai brièvement le sujet des commentaires de code, juste pour établir quelques points qui feront une distinction plus claire.\n",
        "\n",
        "\n",
        " La documentation du code est importante en Python, car étant typé dynamiquement, il peut être facile de se perdre dans les valeurs des variables ou des objets à travers les fonctions et les méthodes. Pour cette raison, indiquer cette information facilitera la tâche des futurs lecteurs du code. Il existe une autre raison qui concerne spéciquement les annotations. Ils peuvent également aider à exécuter certaines vérifications automatiques, telles que l'indication de type, via des outils tels que mypy (http://mypy-lang.org/) ou pytype (https://google.github.io/pytype/). Nous verrons qu'au final, l'ajout d'annotations est payant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Ih0uk6HPAu"
      },
      "source": [
        "## Commentaires sur les codes\n",
        "\n",
        "En règle générale, nous devrions viser à avoir le moins de commentaires de code possible. C'est parce que notre code devrait être auto-documenté. Cela signifie que si nous faisons un effort pour utiliser les bonnes abstractions (comme diviser les responsabilités dans le code entre des fonctions ou des objets significatifs), et que nous nommons les choses clairement, alors les commentaires ne devraient pas être nécessaires.\n",
        "\n",
        "L'opinion exprimée dans cet article à propos des commentaires est à peu près en accord avec le reste de la littérature sur le génie logiciel : les commentaires dans le code sont un symptôme de notre incapacité à exprimer notre code correctement. Cependant, dans certains cas, il est impossible d'éviter d'ajouter un commentaire dans code, et ne pas le faire serait dangereux. C'est généralement le cas lorsque quelque chose dans le code doit être fait pour une nuance technique particulière qui n'est pas triviale à première vue (par exemple, s'il y a un bogue dans une fonction externe sous-jacente et que nous devons passer un paramètre spécial pour contourner le problème ). Dans ce cas, notre mission est d'être le plus concis possible et d'expliquer de la meilleure façon possible quel est le problème, et pourquoi nous prenons ce chemin spécique dans le code afin que le lecteur puisse comprendre la situation.\n",
        "\n",
        "Enfin, il y a un autre type de commentaire dans le code qui est définitivement mauvais, et il n'y a tout simplement aucun moyen de le justifier : le code commenté. Ce code doit être supprimé sans pitié. N'oubliez pas que le code est un langage de communication entre développeurs et qu'il est l'expression ultime de la conception. Le code est la connaissance. Le code commenté apporte le chaos (et très probablement des contradictions) qui polluera cette connaissance.\n",
        "\n",
        "Il n'y a tout simplement aucune bonne raison, surtout maintenant, avec les systèmes de contrôle de version modernes, de laisser le code commenté qui peut être simplement supprimé (ou caché ailleurs). En résumé : les commentaires de code sont mauvais. Parfois un mal nécessaire, mais néanmoins quelque chose que nous devrions essayer d'éviter autant que possible. La documentation sur le code, en revanche, est quelque chose de différent. Cela fait référence à la documentation de la conception ou de l'architecture dans le code lui-même, pour que ce soit clair, et c'est une force positive (et aussi le sujet de la section suivante, dans laquelle nous discutons des docstrings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58uYSss3IhXx"
      },
      "source": [
        "# Docstrings\n",
        "\n",
        "En termes simples, nous pouvons dire que les docstrings sont de la documentation intégrée dans le code source. Une docstring est essentiellement une chaîne littérale, placée quelque part dans le code pour documenter cette partie de la logique. Notez l'accent mis sur le mot documentation. C'est important parce que c'est censé représenter une explication, pas une justification. Les docstrings ne sont pas des commentaires ; ce sont des documents.\n",
        "\n",
        "Les docstrings sont destinés à fournir une documentation pour un composant particulier (un module, une classe, une méthode ou une fonction) dans le code qui sera utile pour d'autres développeurs. \n",
        "\n",
        "L'idée est que lorsque d'autres ingénieurs voudront utiliser le composant que vous écrivez, ils examineront très probablement la docstring pour comprendre comment elle est censée fonctionner, quelles sont les entrées et sorties attendues, etc. Pour cette raison, il est recommandé d'ajouter des docstrings chaque fois que cela est possible. Les docstrings sont également utiles pour documenter les décisions de conception et d'architecture. C'est probablement une bonne idée d'ajouter une chaîne de documentation aux modules, fonctions et classes Python les plus importants afin d'indiquer au lecteur comment ce composant s'intègre dans l'architecture globale. \n",
        "\n",
        "La raison pour laquelle ils sont une bonne chose à avoir dans le code (ou peut-être même requis, selon les normes de votre projet) est que Python est typé dynamiquement. Cela signifie que, par exemple, une fonction peut prendre n'importe quoi comme valeur pour n'importe lequel de ses paramètres. Python n'appliquera ni ne vérifiera quelque chose comme ça. Alors, imaginez que vous trouviez une fonction dans le code que vous savez devoir modifier. Vous avez même la chance que la fonction ait un nom descriptif, et que ses paramètres en fassent autant. Il se peut que les types que vous devriez lui transmettre ne soient toujours pas très clairs. Même si c'est le cas, comment doivent-ils être utilisés ? C'est ici qu'une bonne docstring peut être utile. Documenter les entrées et sorties attendues d'une fonction est une bonne pratique qui aidera les lecteurs de cette fonction à comprendre comment elle est censée fonctionner\n",
        "\n",
        "Ici, la docstring pour la méthode **update**sur les dictionnaires nous donne des informations utiles, et elle nous dit que nous pouvons l'utiliser de différentes manières\n",
        "\n",
        "* **1** Nous pouvons passer quelque chose avec une méthode .keys() (par exemple, un autre dictionnaire), et cela mettra à jour le dictionnaire d'origine avec les clés de l'objet passé par paramètre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT2Kqm6WKFwM",
        "outputId": "63da100a-6031-439c-9a5d-f912b4a8c6a0"
      },
      "source": [
        "d = {}\n",
        "d.update({1: \"one\", 2: \"two\"})\n",
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'one', 2: 'two'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNc3wYtuKUx8"
      },
      "source": [
        "**2** Nous pouvons passer un itérable de paires de clés et de valeurs, et nous allons les déballer pour mettre à jour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjtRjYghKcf5",
        "outputId": "f5baae1d-6855-41b2-fda8-40b464497c22"
      },
      "source": [
        "d.update([(3, \"three\"), (4, \"four\")])\n",
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'one', 2: 'two', 3: 'three', 4: 'four'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTHaJ7hlKqEF"
      },
      "source": [
        "* **3** Cela nous dit également que nous pouvons mettre à jour le dictionnaire avec des valeurs extraites des arguments des mots clés"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npPU_nNpKw3U",
        "outputId": "65eb5226-1127-483b-8888-56f354618012"
      },
      "source": [
        "d.update(five=5)\n",
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'one', 2: 'two', 3: 'three', 4: 'four', 'five': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLJhg5DaK6Ny"
      },
      "source": [
        "(Notez que sous cette forme, les arguments des mots clés sont des chaînes, nous ne pouvons donc pas définir quelque chose sous la forme 5=\"cinq\" car ce serait incorrect.) Cette information est cruciale pour quelqu'un qui veut apprendre et comprendre comment une nouvelle fonction fonctionne, et comment ils peuvent en profiter.\n",
        "\n",
        "Remarquez que dans le premier exemple, nous avons obtenu la docstring de la fonction en utilisant le double point d'interrogation dessus (dict.update??). Il s'agit d'une fonctionnalité de l'interpréteur interactif IPython (https://ipython.org/). Lorsque cela est appelé, il imprimera la docstring de l'objet que vous attendez. Maintenant, imaginez que de la même manière, nous obtenions de l'aide de cette fonction de la bibliothèque standard ; à quel point pourriez-vous faciliter la vie de vos lecteurs (les utilisateurs de votre code), si vous placez des docstrings sur les fonctions que vous écrivez afin que les autres puissent comprendre leur fonctionnement de la même manière ? La docstring n'est pas quelque chose de séparé ou d'isolé du code. Il devient une partie du code et vous pouvez y accéder. Lorsqu'un objet a une docstring définie, celle-ci en fait partie via son attribut __doc__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcRouIu1LPS9"
      },
      "source": [
        "dict.update??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L1BGpBunLst8",
        "outputId": "bd970941-62b3-4a49-e7fb-13a26cc09ac2"
      },
      "source": [
        "def my_function():        \n",
        "  \"\"\"Run some computation\"\"\"\n",
        "  return None\n",
        "\n",
        "my_function.__doc__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Run some computation'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z3GuhmDUzUN"
      },
      "source": [
        "Cela signifie qu'il est même possible d'y accéder au moment de l'exécution et même de générer ou de compiler de la documentation à partir du code source. En fait, il existe des outils pour cela. Si vous exécutez Sphinx, il créera l'échafaudage de base pour la documentation de votre projet. Avec l'extension autodoc (sphinx.ext.autodoc) en particulier, l'outil prendra les docstrings du code et les placera dans les pages qui documentent la fonction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs5I6OpcWEOT"
      },
      "source": [
        "Une fois que vous avez les outils en place pour construire la documentation, rendez-la publique afin qu'elle fasse partie du projet lui-même. Pour les projets open source, vous pouvez utiliser read the docs (https://readthedocs.org/), qui générera automatiquement la documentation par branche ou version (configurable). Pour les entreprises ou les projets, vous pouvez disposer des mêmes outils ou configurer ces services sur site, mais quelle que soit cette décision, l'important est que la documentation soit prête et accessible à tous les membres de l'équipe. , un inconvénient des docstrings, et c'est que, comme c'est le cas pour toute documentation, elle nécessite une maintenance manuelle et constante. Au fur et à mesure que le code change, il devra être mis à jour. Un autre problème est que pour que les docstrings soient vraiment utiles, elles doivent être détaillées, ce qui nécessite plusieurs lignes. Compte tenu de ces deux considérations, si la fonction que vous écrivez est vraiment simple et explicite, il est probablement préférable d'éviter d'ajouter une chaîne de documentation redondante qui nécessitera une maintenance ultérieure. Maintenir une documentation appropriée est un défi d'ingénierie logicielle que nous ne pouvons pas s'échapper. Il est également logique que ce soit comme ça. Si vous y réfléchissez, la raison pour laquelle la documentation doit être écrite manuellement est qu'elle est destinée à être lue par d'autres humains. S'il était automatisé, il ne serait probablement pas d'une grande utilité. Pour que la documentation ait une quelconque valeur, tous les membres de l'équipe doivent convenir qu'il s'agit de quelque chose qui nécessite une intervention manuelle, d'où l'effort requis. La clé est de comprendre que le logiciel n'est pas seulement une question de code. La documentation qui l'accompagne fait également partie du livrable. Par conséquent, lorsque quelqu'un modifie une fonction, il est tout aussi important de mettre également à jour la partie correspondante de la documentation avec le code qui vient d'être modifié, qu'il s'agisse d'un wiki, d'un manuel d'utilisation, d'un fichier README ou plusieurs docstrings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1P5xnK4W4_Q"
      },
      "source": [
        "## Annotations\n",
        "\n",
        "PEP-3107 a introduit le concept d'annotations. L'idée de base est d'indiquer aux lecteurs du code à quoi s'attendre en tant que valeurs d'arguments dans les fonctions. L'utilisation du mot indice n'est pas fortuite ; les annotations permettent l'indication de type, dont nous parlerons plus loin dans cet article, après la première introduction aux annotations. Les annotations vous permettent de spécifier le type attendu de certaines variables qui ont été définies. Il ne s'agit en fait pas seulement des types, mais de tout type de métadonnées qui peuvent vous aider à avoir une meilleure idée de ce que cette variable représente réellement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeA_N6CAXP70"
      },
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Point:\n",
        "    lat: float\n",
        "    long: float\n",
        "  \n",
        "def locate(latitude: float, longitude: float) -> Point:\n",
        "    \"\"\"Find an object in the map by its coordinates\"\"\"\n",
        "    return Point(latitude, longitude)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpnTpFRQnBgq"
      },
      "source": [
        "Ici, nous utilisons float pour indiquer les types attendus de latitude et de longitude. Ceci est simplement informatif pour le lecteur de la fonction afin qu'il puisse se faire une idée de ces types attendus. Python ne vérifiera pas ces types ni ne les appliquera.\n",
        "\n",
        "Nous pouvons également spécifier le type attendu de la valeur renvoyée de la fonction. Dans ce cas, Point est une classe définie par l'utilisateur, cela signifie donc que tout ce qui est renvoyé sera une instance de Point.\n",
        "\n",
        "Nous pouvons tirer parti des annotations pour rendre notre code plus expressif. Prenons l'exemple suivant pour une fonction censée lancer une tâche, mais qui accepte également un paramètre pour différer l'exécution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYrSlM2eXMEf"
      },
      "source": [
        "def launch_task(delay_in_seconds):    \n",
        "  ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CtZ8r4nXUa1"
      },
      "source": [
        "Ici, le nom de l'argument delay_in_seconds semble assez verbeux, mais malgré cela, il ne fournit toujours pas beaucoup d'informations. Qu'est-ce qui constitue de bonnes valeurs acceptables pour les secondes ? Prend-il en compte les fractions.\n",
        "\n",
        "Et si on répondait à ces questions dans le code ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFVac-8DXeSw"
      },
      "source": [
        "Seconds = float\n",
        "def launch_task(delay: Seconds):    \n",
        "  ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9f3qBWhXlOk"
      },
      "source": [
        "Maintenant, le code parle de lui-même. De plus, nous pouvons affirmer qu'avec l'introduction de l'annotation Seconds, nous avons créé une petite abstraction sur la façon dont nous interprétons le temps dans notre code, et nous pouvons réutiliser cette abstraction dans davantage de parties de notre base de code. Si nous décidons plus tard de changer l'abstraction sous-jacente pendant quelques secondes (disons qu'à partir de maintenant, seuls les entiers sont autorisés), nous pouvons faire ce changement en un seul endroit.\n",
        "\n",
        "Avec l'introduction des annotations, un nouvel attribut spécial est également inclus, et il s'agit de __annotations__. Cela nous donnera accès à un dictionnaire qui mappe le nom des annotations (en tant que clés dans le dictionnaire) avec leurs valeurs correspondantes, qui sont celles que nous avons définies pour elles. Dans notre exemple, cela ressemblera à ce qui suit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SYxwOORYQoU",
        "outputId": "4d7ec7d1-d757-4e58-d303-7ebfd62b25a7"
      },
      "source": [
        "launch_task.__annotations__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'delay': float}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVIh0F9aYg_E"
      },
      "source": [
        "Nous pourrions l'utiliser pour générer de la documentation, exécuter des validations ou appliquer des contrôles dans notre code si nous pensons que nous devons\n",
        "\n",
        "En parlant de vérifier le code via des annotations, c'est à ce moment-là que PEP-484 entre en jeu. Ce PEP spécie les bases du type hinting ; l'idée de vérifier les types de nos fonctions via des annotations. Juste pour être clair à nouveau, et en citant PEP-484 lui-même\n",
        "\n",
        "    Python restera un langage à typage dynamique, et les auteurs n'ont aucune envie de rendre les indications de type obligatoires, même par convention\n",
        "\n",
        "L'idée de l'indication de type est d'avoir des outils supplémentaires (indépendants de l'interpréteur) pour vérifier l'utilisation correcte des types dans tout le code et pour indiquer à l'utilisateur si des incompatibilités sont détectées. Il existe des outils utiles qui vérifient les types de données et la façon dont ils sont utilisés dans notre code, afin de détecter les problèmes potentiels. Quelques exemples d'outils, tels que mypy et pytype, sont expliqués plus en détail dans la section Outillage, où nous parlerons de l'utilisation et de la configuration des outils pour le projet. Pour l'instant, vous pouvez le considérer comme une sorte de linter qui vérifiera la sémantique des types utilisés dans le code. Pour cette raison, c'est une bonne idée de configurer mypy ou pytype sur le projet et de l'utiliser au même niveau que le reste des outils d'analyse statique.\n",
        "\n",
        "Cependant, l'indication de type signifie plus qu'un simple outil pour vérifier les types dans notre code. En suivant notre exemple précédent, nous pouvons créer des noms et des abstractions significatifs pour les types de notre code. Considérons le cas suivant pour une fonction qui traite une liste de clients. Dans sa forme la plus simple, il peut être annoté simplement en utilisant une liste générique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97XrpGD6ccIs"
      },
      "source": [
        "\n",
        "def process_clients(clients: list):\n",
        "  ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1LbVbZtcjSx"
      },
      "source": [
        "Nous pouvons ajouter un peu plus de détails si nous savons que dans notre modélisation actuelle des données, les clients sont représentés sous forme de tuples d'entiers et de texte :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PTHHdCNgDQO"
      },
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "def process_clients(clients: List[Tuple[int, str]]):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rli-EXBgNzo"
      },
      "source": [
        "Mais cela ne nous donne toujours pas assez d'informations, il est donc préférable d'être explicite et d'avoir un nom pour cet alias, afin que nous n'ayons pas à déduire ce que ce type signifie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GTEhwzdgU42"
      },
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "Client = Tuple[int, str]\n",
        "def process_clients(clients: List[Client]):\n",
        "  ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSJ24EGmgnUg"
      },
      "source": [
        "Dans ce cas, le sens est plus clair et il prend en charge l'évolution des types de données. Peut-être qu'un tuple est la structure de données minimale qui pose le problème pour représenter correctement un client, mais plus tard, nous voudrons le changer pour un autre objet ou créer une classe spécifique. Et dans ce cas, l'annotation restera correcte, ainsi que toutes les autres vérifications de type.\n",
        "\n",
        "L'idée de base derrière est que maintenant la sémantique s'étend à des concepts plus significatifs, ce qui rend encore plus facile pour nous (humains) de comprendre ce que signifie le code, ou ce qui est attendu à un moment donné\n",
        "\n",
        "\n",
        "Il y a un avantage supplémentaire que les annotations apportent. Avec l'introduction de PEP-526 et PEP-557, il existe un moyen pratique d'écrire des classes de manière compacte et de définir de petits objets conteneurs. L'idée est de simplement déclarer des attributs dans une classe et d'utiliser des annotations pour définir leur type, et avec l'aide du décorateur @dataclass, ils seront traités comme des attributs d'instance sans avoir à le déclarer explicitement dans la méthode __init__ et à définir les valeurs sur eux"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljNuuyEdhO0-",
        "outputId": "b318b0c8-5385-4f77-b39e-fae9af35f346"
      },
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Point:\n",
        "    lat: float\n",
        "    long: float\n",
        "\n",
        "Point.__annotations__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lat': float, 'long': float}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsGVRk9vhduN"
      },
      "source": [
        "Plus tard dans ce repo, nous explorerons d'autres utilisations importantes des annotations, plus liées à la conception du code. Lorsque nous explorons les bonnes pratiques pour la conception orientée objet, nous pouvons souhaiter utiliser des concepts tels que l'injection de dépendances, dans lesquels nous concevons notre code pour qu'il dépende d'interfaces qui déclarent un contrat. Et probablement la meilleure façon de déclarer que le code repose sur une interface particulière est d'utiliser des annotations. Plus précisément, il existe des outils qui utilisent spécifiquement les annotations Python pour fournir automatiquement la prise en charge de l'injection de dépendances.\n",
        "\n",
        "Dans les modèles de conception, nous souhaitons également généralement découpler des parties de notre code d'implémentations spécifiques et nous appuyer sur des interfaces ou des contrats abstraits, pour rendre notre code plus flexible et extensible. De plus, les modèles de conception résolvent généralement les problèmes en créant les abstractions appropriées nécessaires (ce qui signifie généralement avoir de nouvelles classes qui encapsulent une partie de la logique). Dans ces deux scénarios, annoter notre code sera d'une aide supplémentaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT2nkO5PifUf"
      },
      "source": [
        "## Les annotations remplacent-elles les docstrings\n",
        "\n",
        "C'est une question valable, car dans les anciennes versions de Python, bien avant l'introduction des annotations, la façon de documenter les types de paramètres de fonctions ou d'attributs était de mettre des docstrings dessus. Il existe même des conventions pour les formats sur la façon de structurer les docstrings pour inclure les informations de base pour une fonction, y compris les types et la signification de chaque paramètre, la valeur de retour et les exceptions possibles que la fonction pourrait soulever.\n",
        "\n",
        "La plupart de ces problèmes ont déjà été traités de manière plus compacte au moyen d'annotations, on peut donc se demander s'il vaut vraiment la peine d'avoir également des docstrings. La réponse est oui, et c'est parce qu'ils se complètent.\n",
        "\n",
        "Il est vrai qu'une partie des informations précédemment contenues dans la docstring peut désormais être déplacée vers les annotations (il n'y a plus besoin d'indiquer les types des paramètres dans les docstrings car on peut utiliser des annotations). Mais cela ne devrait laisser plus de place pour une meilleure documentation sur la docstring. En particulier, pour les types de données dynamiques et imbriquées, il est toujours judicieux de fournir des exemples des données attendues afin que nous puissions avoir une meilleure idée de ce à quoi nous avons affaire.\n",
        "\n",
        "Considérez l'exemple suivant. Disons que nous avons une fonction qui s'attend à ce qu'un dictionnaire valide certaines données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqnJiPBSjbIm"
      },
      "source": [
        "def data_from_response(response: dict) -> dict:\n",
        "  if response[\"status\"] != 200:\n",
        "    raise ValueError\n",
        "  return {\"data\": response[\"payload\"]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8llpNDYsjoE0"
      },
      "source": [
        "Ici, nous pouvons voir une fonction qui prend un dictionnaire et renvoie un autre dictionnaire. Potentiellement, cela pourrait déclencher une exception si la valeur sous la clé \"status\" n'est pas celle attendue. Cependant, nous n'avons pas beaucoup plus d'informations à ce sujet. Par exemple, à quoi ressemble une instance correcte d'un objet de réponse ? À quoi ressemblerait une instance de résultat ? Pour répondre à ces deux questions, ce serait une bonne idée de documenter des exemples de données qui devraient être transmises par un paramètre et renvoyées par cette fonction.\n",
        "\n",
        "Voyons si nous pouvons mieux expliquer cela à l'aide d'une docstring :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkliGBnTj_Ym"
      },
      "source": [
        "def data_from_response(response: dict) -> dict:\n",
        "    \"\"\"If the response is OK, return its payload.\n",
        "    - response: A dict like::\n",
        "    {\n",
        "        \"status\": 200, # <int>\n",
        "        \"timestamp\": \"....\", # ISO format string of the current date time\n",
        "        \"payload\": { ... } # dict with the returned data\n",
        "    }\n",
        "    - Returns a dictionary like::\n",
        "    {\"data\": { .. } }\n",
        "    - Raises:\n",
        "    - ValueError if the HTTP status is != 200\n",
        "    \"\"\"\n",
        "    if response[\"status\"] != 200:\n",
        "        raise ValueError\n",
        "    return {\"data\": response[\"payload\"]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwGi_KVWkMXE"
      },
      "source": [
        "Maintenant, nous avons une meilleure idée de ce qui devrait être reçu et renvoyé par cette fonction. La documentation est une contribution précieuse, non seulement pour comprendre et se faire une idée de ce qui se passe, mais aussi comme une source précieuse pour les tests unitaires. Nous pouvons dériver des données comme celle-ci à utiliser comme entrée, et nous savons quelles seraient les valeurs correctes et incorrectes à utiliser sur les tests. En fait, les tests fonctionnent également comme une documentation exploitable pour notre code, mais cela sera expliqué plus en détail plus tard dans ce repo.\n",
        "\n",
        "L'avantage est que maintenant nous savons quelles sont les valeurs possibles des clés, ainsi que leurs types, et nous avons une interprétation plus concrète de ce à quoi ressemblent les données. Le coût est que, comme nous l'avons mentionné plus tôt, cela prend beaucoup de lignes, et il doit être verbeux et détaillé pour être efficace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBWJyqpilMdW"
      },
      "source": [
        "## Outillage\n",
        "\n",
        "Dans cette section, nous allons explorer comment configurer certains outils de base et exécuter automatiquement des vérifications sur le code, dans le but de tirer parti d'une partie des vérifications répétitives.\n",
        "\n",
        "C'est un point important : rappelez-vous que le code est pour nous, les gens, à comprendre, donc nous seuls pouvons déterminer ce qui est bon ou mauvais. Nous devons investir du temps dans les revues de code, réfléchir à ce qu'est un bon code et à quel point il est lisible et compréhensible. Lorsque vous regardez le code écrit par un pair, vous devriez poser des questions telles que:\n",
        "\n",
        "* Ce code est-il facile à comprendre et à suivre pour un collègue programmeur ?\n",
        "*  S'exprime-t-il en termes de domaine du problème ?\n",
        "* Une nouvelle personne rejoignant l'équipe serait-elle capable de le comprendre et de l'utiliser efficacement ?\n",
        "\n",
        "Comme nous l'avons vu précédemment, le formatage du code, la mise en page cohérente et l'indentation appropriée sont nécessaires mais pas sufsants pour avoir des caractéristiques dans une base de code. De plus, ce sont des choses que nous, en tant qu'ingénieurs avec un sens élevé de la qualité, considérerions comme allant de soi, donc nous lirons et écrirons du code bien au-delà des concepts de base de sa mise en page. Par conséquent, nous ne sommes pas disposés à perdre du temps à examiner ce type d'éléments, nous pouvons donc investir notre temps plus efficacement en examinant les modèles réels du code afin de comprendre sa véritable signification et de fournir des résultats précieux.\n",
        "\n",
        "Tous ces contrôles devraient être automatisés. Ils devraient faire partie des tests ou de la liste de contrôle, et cela, à son tour, devrait faire partie de la construction d'intégration continue. Si ces vérifications échouent, faites échouer la génération. C'est le seul moyen d'assurer réellement la continuité de la structure du code à tout moment. Il sert également de paramètre objectif pour l'équipe à avoir comme référence. Au lieu d'avoir des ingénieurs ou le chef d'équipe qui doivent toujours signaler les mêmes commentaires sur PEP-8 lors des revues de code, la construction échouera automatiquement, ce qui en fera quelque chose d'objectif.\n",
        "\n",
        "Les outils présentés dans cette section vous donneront une idée des vérifications que vous pourriez effectuer automatiquement sur le code. Ces outils devraient appliquer certaines normes. En général, ils sont configurables, et il serait parfaitement normal que chaque référentiel ait sa propre configuration.\n",
        "\n",
        "L'idée d'utiliser des outils est d'avoir une manière reproductible et automatique d'exécuter certaines vérifications. Cela signifie que chaque ingénieur doit être capable d'exécuter les outils sur son environnement de développement local et d'atteindre les mêmes résultats que n'importe quel autre membre de l'équipe. Et aussi, que ces outils doivent être configurés dans le cadre de la construction d'intégration continue (CI)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB05j5wDm6zD"
      },
      "source": [
        "### Vérification de la cohérence des types\n",
        "\n",
        "La cohérence des types est l'une des principales choses que nous aimerions vérifier automatiquement. Python est typé dynamiquement, mais nous pouvons toujours ajouter des annotations de type pour indiquer aux lecteurs (et aux outils) à quoi s'attendre dans différentes parties du code. Même si les annotations sont facultatives, comme nous l'avons vu, leur ajout est une bonne idée non seulement parce que cela rend le code plus lisible, mais aussi parce que nous pouvons ensuite utiliser des annotations ainsi que des outils pour vérifier automatiquement certaines erreurs courantes les plus probables. Bugs.\n",
        "\n",
        "Depuis l'introduction de l'indication de type dans Python, de nombreux outils de vérification de la cohérence des types ont été développés. Dans cette section, nous en examinerons deux : mypy (https://github.com/python/mypy) et pytype (https://github.com/google/pytype). Il existe plusieurs outils, et vous pouvez même choisir d'en utiliser un autre, mais en général, les mêmes principes s'appliquent quel que soit l'outil spécique : l'important est d'avoir un moyen automatique de valider les changements, et d'ajouter ces validations comme partie de la construction CI. mypy est l'outil principal pour la vérification de type statique facultative en Python. L'idée est qu'une fois installé, il analysera tous les fichiers de votre projet, en vérifiant les incohérences dans l'utilisation des types. C'est utile car, la plupart du temps, cela détectera les bogues réels tôt, mais parfois cela peut donner des faux positifs.\n",
        "\n",
        "Vous pouvez l'installer avec pip, et il est recommandé de l'inclure en tant que dépendance du projet sur le fichier d'installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSJxCl9QnrN3",
        "outputId": "df28fdfb-5ea8-46be-dcfa-bf723aa6a66d"
      },
      "source": [
        "pip install mypy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mypy\n",
            "  Downloading mypy-0.910-cp37-cp37m-manylinux2010_x86_64.whl (21.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5 MB 8.4 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions<0.5.0,>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from mypy) (3.7.4.3)\n",
            "Collecting typed-ast<1.5.0,>=1.4.0\n",
            "  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from mypy) (0.10.2)\n",
            "Installing collected packages: typed-ast, mypy-extensions, mypy\n",
            "Successfully installed mypy-0.910 mypy-extensions-0.4.3 typed-ast-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h-nBGDenwSP"
      },
      "source": [
        "Une fois qu'il est installé dans l'environnement virtuel, il vous suffit d'exécuter la commande précédente et il rapportera tous les résultats sur les vérifications de type. Essayez d'adhérer autant que possible à son rapport, car la plupart du temps, les informations fournies par celui-ci permettent d'éviter des erreurs qui pourraient autrement se glisser dans la production. Cependant, l'outil n'est pas parfait, donc si vous pensez qu'il signale un faux positif, vous pouvez ignorer cette ligne avec le marqueur suivant comme commentaire\n",
        "\n",
        "    type_to_ignore = \"something\" # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU1sl3XYoWGg"
      },
      "source": [
        "Il est important de noter que pour que cet outil ou tout autre outil soit utile, nous devons faire attention aux annotations de type que nous déclarons dans le code. Si nous sommes trop génériques avec les types définis, nous pourrions manquer certains cas dans lesquels l'outil pourrait signaler des problèmes légitimes.\n",
        "\n",
        "Dans l'exemple suivant, il existe une fonction destinée à recevoir un paramètre à itérer. À l'origine, tout itérable fonctionnerait, nous voulons donc tirer parti des capacités de typage dynamique de Python et autoriser une fonction qui peut utiliser des listes de passage, des tuples, des clés de dictionnaires, des ensembles ou à peu près tout ce qui prend en charge une boucle for"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFTUgTLqoxJC"
      },
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "from typing import List, Union, Tuple\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def broadcast_notification(\n",
        "    message: str, relevant_user_emails: Union[List[str], Tuple[str]]\n",
        "):\n",
        "    for email in relevant_user_emails:\n",
        "        logger.info(\"Sending %r to %r\", message, email)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igkQqjP9pPVk"
      },
      "source": [
        "Le problème est que si une partie du code passe ces paramètres par erreur, mypy ne signalera pas d'erreur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgWigTkUpXf3",
        "outputId": "a739e50f-3308-4b49-8591-a6a23d6fe240"
      },
      "source": [
        "broadcast_notification(\"welcome\", \"user1@domain.com\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Sending 'welcome' to 'u'\n",
            "INFO:__main__:Sending 'welcome' to 's'\n",
            "INFO:__main__:Sending 'welcome' to 'e'\n",
            "INFO:__main__:Sending 'welcome' to 'r'\n",
            "INFO:__main__:Sending 'welcome' to '1'\n",
            "INFO:__main__:Sending 'welcome' to '@'\n",
            "INFO:__main__:Sending 'welcome' to 'd'\n",
            "INFO:__main__:Sending 'welcome' to 'o'\n",
            "INFO:__main__:Sending 'welcome' to 'm'\n",
            "INFO:__main__:Sending 'welcome' to 'a'\n",
            "INFO:__main__:Sending 'welcome' to 'i'\n",
            "INFO:__main__:Sending 'welcome' to 'n'\n",
            "INFO:__main__:Sending 'welcome' to '.'\n",
            "INFO:__main__:Sending 'welcome' to 'c'\n",
            "INFO:__main__:Sending 'welcome' to 'o'\n",
            "INFO:__main__:Sending 'welcome' to 'm'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg4tB08op43N"
      },
      "source": [
        "Et bien sûr, ce n'est pas une instance valide car elle itérera chaque caractère de la chaîne et essaiera de l'utiliser comme e-mail.\n",
        "\n",
        "Si à la place, nous sommes plus restrictifs avec les types définis pour ce paramètre (disons pour n'accepter que des listes ou des tuples de chaînes), alors l'exécution de mypy identifie ce scénario erroné.\n",
        "\n",
        "    mypy <file-name>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfFDUp3puqzj"
      },
      "source": [
        "De même, pytype est également configurable et fonctionne de manière similaire, vous pouvez donc adapter les deux outils au contexte spécique de votre projet. Nous pouvons voir comment l'erreur signalée par cet outil est très similaire au cas précédent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTf5c6kavEsR"
      },
      "source": [
        "Une différence clé que pytype a cependant, est qu'il ne se contentera pas de vérifier les définitions par rapport aux arguments, mais essaiera d'interpréter si le code à l'exécution sera correct et signalera quelles seraient les erreurs d'exécution. Par exemple, si l'une des définitions de type est temporairement violée, cela ne sera pas considéré comme un problème tant que le résultat final est conforme au type déclaré. Bien que ce soit un trait agréable, en général, je vous recommanderais d'essayer de ne pas casser les invariants que vous avez définis dans le code et d'éviter autant que possible les états invalides intermédiaires, car cela rendra votre code plus facile à raisonner et comptera sur moins Effets secondaires"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eGIU4xVvc3G"
      },
      "source": [
        "## Validations génériques dans le code\n",
        "\n",
        "En plus d'utiliser des outils comme ceux introduits dans la section précédente, pour vérifier les erreurs sur la gestion des types de notre programme, nous pouvons utiliser d'autres outils qui fourniront des validations par rapport à un plus large éventail de paramètres.\n",
        "\n",
        "Il existe de nombreux outils pour vérifier la structure du code (essentiellement, il s'agit de la conformité avec PEP-8) en Python, tels que pycodestyle (anciennement connu sous le nom de pep8 dans PyPi), flake8 et bien d'autres. Ils sont tous configurables et sont aussi simples à utiliser que l'exécution de la commande qu'ils fournissent.\n",
        "\n",
        "Ces outils sont des programmes qui s'exécutent sur un ensemble de fichiers Python et vérifient la conformité du code par rapport à la norme PEP-8, en signalant chaque ligne enfreinte et l'erreur indicative de la règle qui a été enfreinte.\n",
        "\n",
        "Il existe d'autres outils qui fournissent des contrôles plus complets de sorte qu'au lieu de simplement valider la conformité avec PEP-8, ils incluent également des contrôles supplémentaires pour des situations plus compliquées qui dépassent PEP-8 (rappelez-vous, le code peut toujours être totalement conforme à PEP-8 et toujours pas de bonne qualité).\n",
        "\n",
        "Par exemple, PEP-8 concerne principalement le style et la structuration de notre code, mais il ne nous oblige pas à mettre une docstring sur chaque méthode, classe ou module public. Cela ne dit rien non plus sur une fonction qui prend trop de paramètres ).\n",
        "\n",
        "\n",
        "Un exemple d'un tel outil est pylint. C'est l'un des outils les plus complets et les plus stricts pour valider les projets Python, et il est également configurable. Comme précédemment, pour l'utiliser, il suffit de l'installer dans l'environnement virtuel avec pip\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69tPTjrwwnV9"
      },
      "source": [
        "!pip install pylint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygOlXAkhwsmI"
      },
      "source": [
        "Ensuite, il suffirait de lancer la commande pylint pour le vérifier dans le code. Il est possible de congurer pylint via un chier de configuration nommé pylintrc. Dans ce chier, vous pouvez décider des règles que vous souhaitez activer ou désactiver, et en paramétrer d'autres (par exemple, pour modifier la longueur maximale de la colonne). Par exemple, comme nous venons de l'expliquer, nous pourrions ne pas vouloir que chaque fonction ait une docstring, car forcer cela pourrait être contre-productif. Cependant, par défaut, pylint imposera cette restriction, mais nous pouvons l'annuler dans le fichier de configuration en la déclarant\n",
        "\n",
        "    [DESIGN]\n",
        "    disable=missing-function-docstring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XsmhZZjxFfu"
      },
      "source": [
        "Une fois que ce fichier de configuration a atteint un état stable (c'est-à-dire qu'il est aligné sur les directives de codage et ne nécessite pas beaucoup de réglages supplémentaires), il peut alors être copié dans le reste des référentiels, où il devrait également être sous contrôle de version.\n",
        "\n",
        "Enfin, il y a un autre outil que je voudrais mentionner, et c'est Coala (https://github.com/coala/coala). Coala est un peu plus générique (ce qui signifie qu'il prend en charge plusieurs langages, pas seulement Python), mais l'idée est similaire à la précédente : il faut un fichier de configuration, puis il présente un outil en ligne de commande qui exécutera certains vérifie le code. Lors de l'exécution, si l'outil détecte des erreurs lors de l'analyse des fichiers, il peut en informer l'utilisateur et suggérer d'appliquer automatiquement un correctif de xation, le cas échéant.\n",
        "\n",
        "Mais que se passe-t-il si j'ai un cas d'utilisation qui n'est pas couvert par les règles par défaut des outils ? pylint et Coala sont tous deux fournis avec de nombreuses règles prédéfinies qui couvrent les scénarios les plus courants, mais vous pouvez toujours détecter dans votre organisation un modèle qui a conduit à des erreurs. Si vous détectez un modèle récurrent dans le code, c'est une erreur. sujettes, je suggère d'investir du temps dans la dénition de vos propres règles. Ces deux outils sont extensibles : dans le cas de pylint, plusieurs plugins sont disponibles et vous pouvez écrire le vôtre. Dans le cas de Coala, vous pouvez écrire vos propres modules de validation à exécuter en parallèle des contrôles réguliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3gGgAg9xtDD"
      },
      "source": [
        "##Formatage automatique\n",
        "\n",
        "Comme mentionné au début, il serait sage que l'équipe se mette d'accord sur une convention d'écriture pour le code, pour éviter de discuter des préférences personnelles sur les pull request, et se concentrer sur l'essence du code. Mais l'accord ne vous mènerait pas loin, et si ces règles ne sont pas appliquées, elles se perdront avec le temps.\n",
        "\n",
        "Outre la simple vérification du respect des normes à l'aide d'outils, il serait utile de formater automatiquement le code directement.\n",
        "\n",
        "Il existe plusieurs outils qui formatent automatiquement le code Python (par exemple, la plupart des outils qui valident PEP-8, comme flake8, ont également un mode pour réécrire le code et le rendre conforme à PEP-8), et ils sont également configurable et adaptable à chaque projet spécique. Parmi ceux-ci, et peut-être à cause de tout le contraire d'une flexibilité et d'une conguration totales, il y en a un que je voudrais souligner : **black**\n",
        "\n",
        "black (https://github.com/psf/black) a la particularité de formater le code de manière unique et déterministe, sans autoriser aucun paramètre (sauf peut-être, la longueur des lignes)\n",
        "\n",
        "\n",
        "Un exemple de ceci est que black formatera toujours les chaînes en utilisant des guillemets doubles, et l'ordre des paramètres suivra toujours la même structure. Cela peut sembler rigide, mais c'est le seul moyen de s'assurer que les différences dans le code sont réduites au minimum. Si le code respecte toujours la même structure, les modifications du code n'apparaîtront que dans les demandes d'extraction avec les modifications réelles qui ont été apportées, et aucune modification cosmétique supplémentaire. C'est plus restrictif que PEP-8, mais c'est aussi pratique car, en formatant le code directement via un outil, nous n'avons pas à nous en préoccuper et nous pouvons nous concentrer sur le nœud du problème.\n",
        "\n",
        "C'est aussi la raison pour laquelle le black existe. PEP-8 définit quelques directives pour structurer notre code, mais il existe plusieurs façons d'avoir un code conforme à PEP-8, donc il y a toujours le problème de trouver des différences de style. La façon dont le noir formate le code consiste à le déplacer vers un sous-ensemble plus strict de PEP-8 qui est toujours déterministe\n",
        "\n",
        "A titre d'exemple, voyez que le code suivant est compatible PEP-8, mais il ne suit pas les conventions de black"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du1rr8ItKUUo"
      },
      "source": [
        "def my_function(name):\n",
        "  \"\"\"    \n",
        "  >>> my_function('black')    \n",
        "  'received Black'    \n",
        "  \"\"\"    \n",
        "  return 'received {0}'.format(name.title())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBr6OTxyKgiN"
      },
      "source": [
        "Maintenant, nous pouvons exécuter la commande suivante pour formater le fichier\n",
        "\n",
        "    black -l 79 *.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq6OFsa2LBxs"
      },
      "source": [
        "Et nous pouvons voir ce que l'outil a écrit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUZyadC5LIfC"
      },
      "source": [
        "def my_function(name):\n",
        "  \"\"\"    \n",
        "  >>> my_function('black')\n",
        "  'received Black'    \n",
        "  \"\"\"    \n",
        "  return \"received {0}\".format(name.title())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5ZlMZSZLcgY"
      },
      "source": [
        "Sur un code plus complexe, beaucoup plus aurait changé (virgules de fin, et plus), mais l'idée peut être vue clairement. Encore une fois, c'est opiniâtre, mais c'est aussi une bonne idée d'avoir un outil qui s'occupe des détails pour nous.\n",
        "\n",
        "C'est aussi quelque chose que la communauté Golang a appris il y a longtemps, au point qu'il existe une bibliothèque d'outils standard, go fmt, qui formate automatiquement le code selon les conventions du langage. C'est bien que Python ait quelque chose comme ça maintenant.\n",
        "\n",
        "Une fois installée, la commande 'black', par défaut, tentera de formater le code, mais elle a également une option '--check' qui validera le fichier par rapport à la norme et échouera le processus s'il ne réussit pas la validation. Cette commande est un bon candidat à avoir dans le cadre des vérifications automatiques et du processus CI.\n",
        "\n",
        "Il convient de mentionner que black formatera soigneusement un fichier et qu'il ne prend pas en charge le formatage partiel (contrairement à d'autres outils). Cela peut être un problème pour les projets hérités qui ont déjà du code avec un style différent, car si vous souhaitez adopter BLACK comme norme de formatage dans votre projet, vous devrez probablement accepter l'un de ces deux scénarios.\n",
        "\n",
        "* **1** Création d'une demande pul request qui appliquera le format black à tous les fichiers Python du référentiel. Cela a pour inconvénients d'ajouter beaucoup de bruit et de polluer l'historique de contrôle de version du repo. Dans certains cas, votre équipe peut décider d'accepter le risque (en fonction de combien vous comptez sur l'historique git)\n",
        "\n",
        "* **2** Alternativement, vous pouvez réécrire l'historique avec les modifications du code avec le format black appliqué. Dans git, il est possible de réécrire les commits (dès le début), en appliquant des commandes sur chaque commit. Dans ce cas, nous pouvons réécrire chaque commit après que le formatage « noir » ait été appliqué. En fin de compte, il semblerait que le projet ait été sous une nouvelle forme depuis le tout début, mais il y a quelques mises en garde. Pour commencer, l'historique du projet a été réécrit, donc tout le monde devra actualiser ses copies locales du référentiel. Et deuxièmement, selon l'historique de votre référentiel, s'il y a beaucoup de commits, ce processus peut prendre un certain temps.\n",
        "\n",
        "\n",
        "Dans les cas où le formatage à la mode \"tout ou rien\" n'est pas acceptable, on peut utiliser yapf (https://github.com/google/yapf), qui est un autre outil qui présente de nombreuses différences par rapport au black : c'est hautement personnalisable, et il accepte également le formatage partiel (en appliquant le formatage uniquement à certaines régions du script)\n",
        "\n",
        "yapf accepte un argument pour spécifier la plage des lignes auxquelles appliquer le formatage. Avec cela, vous pouvez configurer votre éditeur ou IDE (ou mieux encore, configurer un hook git pre-commit), pour formater automatiquement le code uniquement sur les régions du code qui viennent d'être modifiées. De cette façon, le projet peut s'aligner sur les normes de codage, à intervalles échelonnés, au fur et à mesure que des modifications sont apportées\n",
        "\n",
        "\n",
        "Pour conclure cette section sur les outils qui formatent le code automatiquement, nous pouvons dire que black est un excellent outil qui poussera le code vers un standard canonique, et pour cette raison, vous devriez essayer de l'utiliser dans vos référentiels. Il n'y a absolument aucune friction avec l'utilisation du black sur les nouveaux référentiels créés, mais il est également compréhensible que pour les référentiels hérités, cela puisse devenir un obstacle. Si l'équipe décide qu'il est tout simplement trop fastidieux d'adopter le black dans un référentiel hérité, des outils tels que yapf pourraient être plus adaptés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu6XnjVJNwn6"
      },
      "source": [
        "## Paramétrage des contrôles automatiques\n",
        "\n",
        "Dans les environnements de développement Unix, la manière la plus courante de travailler est via Makefiles. Les makefiles sont des outils puissants qui nous permettent de configurer les commandes à exécuter dans le projet, principalement pour la compilation, l'exécution, etc. En plus de cela, nous pouvons utiliser un Makefile à la racine de notre projet, avec quelques commandes configurées pour exécuter des vérifications sur la mise en forme et les conventions du code, automatiquement.\n",
        "\n",
        "Une bonne approche pour cela serait d'avoir des cibles pour les tests, et chaque test particulier, puis d'en avoir un autre qui s'exécute complètement ; par exemple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0muHijeaOTo6"
      },
      "source": [
        ".PHONY: typehint\n",
        "typehint:\n",
        "\tmypy --ignore-missing-imports src/\n",
        "\n",
        ".PHONY: test\n",
        "test:\n",
        "\tpytest tests/\n",
        "\n",
        ".PHONY: lint\n",
        "lint:\n",
        "\tpylint src/\n",
        "\n",
        ".PHONY: checklist\n",
        "checklist: lint typehint test\n",
        "\n",
        ".PHONY: black\n",
        "black:\n",
        "\tblack -l 79 *.py\n",
        "\n",
        ".PHONY: clean\n",
        "clean:\n",
        "\tfind . -type f -name \"*.pyc\" | xargs rm -fr\n",
        "\tfind . -type d -name __pycache__ | xargs rm -fr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJo_Rh6wOS-s"
      },
      "source": [
        "Ici, la commande que nous exécutons (à la fois sur nos machines de développement et sur les versions de l'environnement CI) est la suivante\n",
        "\n",
        "    make checklist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozO7B2RDO5iZ"
      },
      "source": [
        "Cela exécutera tout dans les étapes suivantes\n",
        "\n",
        "Il vérifiera d'abord la conformité avec la directive de codage (PEP-8, ou black avec le paramètre '--check', par exemple).\n",
        "\n",
        "2. Ensuite, il vérifiera l'utilisation de types sur le code.\n",
        "\n",
        "3. Enfin, il exécutera les tests\n",
        "\n",
        "Si l'une de ces étapes échoue, considérez l'ensemble du processus comme un échec\n",
        "\n",
        "\n",
        "Ces outils (black, pylint, mypy et bien d'autres) peuvent être intégrés à l'éditeur ou à l'IDE de votre choix pour rendre les choses encore plus faciles. C'est un bon investissement de configurer votre éditeur pour faire ce genre de modifications soit lors de l'enregistrement du fichier soit via un raccourci. il existe un moyen simple et unique d'effectuer automatiquement les tâches les plus répétitives. Les nouveaux membres de l'équipe peuvent rapidement s'intégrer en apprenant que quelque chose comme « make format » formate automatiquement le code quel que soit l'outil sous-jacent (et ses paramètres) utilisé. De plus, s'il est décidé plus tard de changer d'outil (disons que vous passez de yapf au noir), alors la même commande (\"make format\") serait toujours valide. Deuxièmement, il est bon d'exploiter autant le Makefile que possible, et cela signifie congurer votre outil CI pour appeler également les commandes dans le Makefile. De cette façon, il existe une manière standardisée d'exécuter les tâches principales de votre projet, et nous plaçons le moins de configuration possible dans l'outil CI (qui, encore une fois, pourrait changer à l'avenir, et cela ne doit pas être un problème majeur charge)."
      ]
    }
  ]
}